{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import praw\n",
    "import os\n",
    "import seaborn as sns\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "user_agent = \"Trump defo 1.0 by /u/speedylean\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id = os.getenv('REDDIT_ID'),\n",
    "    client_secret = os.getenv('REDDIT_SECRET'),\n",
    "    user_agent = \"not a bot\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trump scraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import os\n",
    "import praw\n",
    "import pandas as pd\n",
    "import re\n",
    "from prawcore.exceptions import TooManyRequests, RequestException\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# filtros trump\n",
    "trump_keywords = [\n",
    "    'donald trump', 'trump', 'donald', 'donaldtrump', \n",
    "    'orange', 'duck', 'donaldduck', 'donald duck', \n",
    "    'donnybaby', 'donnyboy', 'donnybrook', 'trumpinator', \n",
    "    'trumpamaniac', 'trumpastrophie', 'trumpocalypse', \n",
    "    'trumpenstein', 'trumpletoes', 'tricky trump', \n",
    "    'pumpkin', 'corn', 'president trump', \n",
    "    'drumpf', 'the donald', 'mr. trump', 'potus'\n",
    "    ]\n",
    "trump_keywords = [keyword.lower() for keyword in trump_keywords]\n",
    "\n",
    "# filtros trumpers\n",
    "trumpers_keywords = [\n",
    "    'mike pence', 'pence', 'mike', 'mikepence',\n",
    "    'ron desantis', 'desantis', 'ron', 'rondesantis',\n",
    "    'marjorie taylor greene', 'mtg', 'greene', 'marjorie',\n",
    "    'lauren boebert', 'boebert', 'lauren',\n",
    "    'ted cruz', 'cruz', 'ted', 'tedcruz',\n",
    "    'mitch mcconnell', 'mcconnell', 'mitch', 'mcconnell',\n",
    "    'lindsey graham', 'graham', 'lindsey', 'lindseygraham',\n",
    "    'kevin mccarthy', 'mccarthy', 'kevin', 'kevinmccarthy',\n",
    "    'rudy giuliani', 'giuliani', 'rudy', 'rudygiuliani',\n",
    "    'steve bannon', 'bannon', 'steve', 'stevebannon',\n",
    "    'michael flynn', 'flynn', 'michael', 'michaelflynn',\n",
    "    'roger stone', 'roger', 'stone', 'rogerstone',\n",
    "    'matt gaetz', 'gaetz', 'matt', 'mattgaetz',\n",
    "    'sean hannity', 'hannity', 'sean', 'seanhannity'\n",
    "    ]\n",
    "trumpers_keywords = [keyword.lower() for keyword in trumpers_keywords]\n",
    "\n",
    "# filtros kamala\n",
    "kamala_keywords = [\n",
    "    'kamala harris', 'kamala', 'harris', 'kamalaharris', \n",
    "    'vice president harris', 'vp harris', 'kammie', \n",
    "    'kammy', 'kamalalal', 'kamalita', 'mrs. harris', 'ms. harris'\n",
    "    'Comrade Kamala', 'Crazy Kamala', 'Laffin Kamala', 'Lying Kamala Harris', 'Kamabla'\n",
    "    ]\n",
    "kamala_keywords = [keyword.lower() for keyword in kamala_keywords]\n",
    "\n",
    "# filtros kamalers\n",
    "kamalers_keywords = [\n",
    "\n",
    "    'nancy pelosi', 'pelosi', 'nancy', 'nancypelosi',\n",
    "    'chuck schumer', 'schumer', 'chuck', 'chuckschumer',\n",
    "    'elizabeth warren', 'warren', 'elizabeth', 'elizabethwarren',\n",
    "    'bernie sanders', 'sanders', 'bernie', 'berniesanders',\n",
    "    'aoc', 'alexandria ocasio-cortez', 'ocasio-cortez', 'alexandria',\n",
    "    'pete buttigieg', 'buttigieg', 'pete', 'petebuttigieg',\n",
    "    'gavin newsom', 'newsom', 'gavin', 'gavinnewsom',\n",
    "    'cory booker', 'booker', 'cory', 'corybooker',\n",
    "    'stacey abrams', 'abrams', 'stacey', 'staceyabrams',\n",
    "    'hillary', 'michelle obama', 'michelle', 'michelleobama',\n",
    "    'keisha lance bottoms', 'keisha', 'lance bottoms', 'keisha lance'\n",
    "]\n",
    "kamalers_keywords = [keyword.lower() for keyword in kamalers_keywords]\n",
    "\n",
    "democrats_keywords = [\n",
    "    'democrat', 'democrats', 'dem party', 'democratic party',\n",
    "    'dnc', 'liberal', 'liberals', 'left', 'leftist', \n",
    "    'progressive', 'progressives', 'blue', 'blue wave', \n",
    "    'blue states', 'donkey', 'donkeys', 'libtard', \n",
    "    'libs', 'snowflake', 'snowflakes', 'blue team',\n",
    "    'the left', 'dem establishment', 'biden administration', \n",
    "    'left-wing', 'democrat-controlled', 'blue collar',\n",
    "    'progressive caucus', 'leftists', 'dem agenda'\n",
    "]\n",
    "democrats_keywords = [keyword.lower() for keyword in democrats_keywords]\n",
    "\n",
    "republicans_keywords = [\n",
    "    'republican', 'republicans', 'gop', 'grand old party',\n",
    "    'conservative', 'conservatives', 'right', 'right-wing',\n",
    "    'red', 'red wave', 'red states', 'elephant', \n",
    "    'elephants', 'right-winger', 'right-wingers', \n",
    "    'maga', 'make america great again', 'trump party', \n",
    "    'gop establishment', 'rnc', 'red team', \n",
    "    'the right', 'republican-controlled', 'republican agenda'\n",
    "]\n",
    "republicans_keywords = [keyword.lower() for keyword in republicans_keywords]\n",
    "\n",
    "# haciendo logging para monitorear errores de rate-limit y retries\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s', handlers = [logging.StreamHandler(), logging.FileHandler(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\logs\\all_hotscraper_v4.log\", mode= 'a')])\n",
    "\n",
    "\n",
    "# Inicializando Reddit\n",
    "load_dotenv()\n",
    "user_agent = \"political_research 3.0 by /u/speedylean\"\n",
    "reddit = praw.Reddit(\n",
    "    client_id = os.getenv('REDDIT_ID'),\n",
    "    client_secret = os.getenv('REDDIT_SECRET'),\n",
    "    user_agent = user_agent\n",
    ")\n",
    "\n",
    "# funcion para checkear si tiene keyword\n",
    "def contains_trump_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in trump_keywords)\n",
    "def contains_trumper_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in trumpers_keywords)\n",
    "def contains_kamala_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in kamala_keywords)\n",
    "def contains_kamaler_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in kamalers_keywords)\n",
    "def contains_democrat_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in democrats_keywords)\n",
    "def contains_republican_keyword(text):\n",
    "    return any(keyword in text.lower() for keyword in republicans_keywords)\n",
    "\n",
    "\n",
    "def is_relevant_content(text):\n",
    "    text = text.lower()\n",
    "    # frases comunes de bots:\n",
    "    bot_phrases = [\n",
    "        \"i am a bot\", \"this bot\", \"automoderator\", \n",
    "        \"bot created\", \"beep boop\", \"bleep bloop\", \n",
    "        \"bot detected\", \"this is a reminder from the bots\",\n",
    "        \"your post has been removed\", \"your comment has been removed\", \n",
    "        \"moderator action\", \"subreddit rules\", \n",
    "        \"thank you for your submission\", \"follow the subreddit rules\", \n",
    "        \"please read our community guidelines\", \"crosspost\", \"x-post\"\n",
    "    ]\n",
    "\n",
    "    # filtering comments that contain these phrases\n",
    "    if any(phrase in text for phrase in bot_phrases):\n",
    "        return False\n",
    "    \n",
    "    # filter out urls\n",
    "    if re.search(r'http[s]?://', text):\n",
    "        return False\n",
    "    \n",
    "    # filtering out short generic comments\n",
    "    if len(text) < 20 or text in ['thanks', 'lol', 'ok', 'i agree']:\n",
    "        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "# definiendo la lista de subreddits:\n",
    "subreddits = ['SocialDemocracy', 'USPolitics', 'Libertarian', 'ConservativesOnly', 'OurPresident', 'Socialism', 'WayOfTheBern', 'politics', 'PoliticalDiscussion', 'Conservative', 'Liberal', 'ModeratePolitics', 'Ask_Politics', 'Democrats', 'Republican']\n",
    "\n",
    "# columnas del dataframe\n",
    "columns = ['text', 'submission_type', 'subreddit', 'labels', 'id']\n",
    "\n",
    "# Iniciando variables de backoff:\n",
    "initial_backoff = 5\n",
    "max_backoff = 300\n",
    "backoff_factor = 2\n",
    "\n",
    "output_file = r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\all_hotscrape_v4.csv\"\n",
    "\n",
    "# funcion para guardar progreso y liberar memoria\n",
    "def save_progress(df):\n",
    "    global i\n",
    "    if not df.empty: # guardar solo si NO está vacío\n",
    "        try:\n",
    "            logging.info(f\"Saving current progress...\")\n",
    "            # checkeamos si el df existe antes de guardarlo:\n",
    "            file_exists = os.path.isfile(output_file)\n",
    "\n",
    "            # si existe guardamos SIN headers:\n",
    "            df.to_csv(output_file, mode='a', header=not file_exists, index=False)\n",
    "            logging.info(f\"Saved {len(df)} records successfully. i = {i}\")\n",
    "\n",
    "            # no limpiamos el buffer aquí?\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error saving progress: {e}\")\n",
    "            logging.info(f\"df.shape = {df.shape}, i = {i}\")\n",
    "\n",
    "def backoff_sleep(attempt):\n",
    "    sleep_time = min(initial_backoff * (backoff_factor ** attempt), max_backoff)\n",
    "    logging.info(f\"Rate limit hit. Sleeping for {sleep_time} seconds...\")\n",
    "    time.sleep(sleep_time)\n",
    "\n",
    "# funcion scrapeadora:\n",
    "# daily avg posts in subreddit = 400 (one week = 2400)\n",
    "limit = None # automatic limit is 1000\n",
    "\n",
    "def all_hotscraped():\n",
    "    global initial_backoff, i\n",
    "    i = 0\n",
    "    records_collected = 0\n",
    "    n_unique_posts = 0\n",
    "    save_threshold = 50000\n",
    "    df_buffer = pd.DataFrame(columns=columns)\n",
    "\n",
    "    # loopeando y filtrando subreddits, posts, comments y replies\n",
    "    for subreddit in subreddits:\n",
    "        subreddit_name = subreddit\n",
    "        subreddit = reddit.subreddit(subreddit)\n",
    "        logging.info(f\"Now scraping r/{subreddit_name}\")\n",
    "        id_list = []\n",
    "\n",
    "        # scrappear los posts dentro de un while loop para manejar los errores y reintentos\n",
    "        attempt = 0\n",
    "        while True:\n",
    "            try:\n",
    "                posts = list(subreddit.hot(limit=limit))\n",
    "                logging.info(f\"Fetched {len(posts)} posts from r/{subreddit_name}\")\n",
    "                n_unique_posts += len(posts)\n",
    "                break  # en caso de éxito salimos del loop\n",
    "            except TooManyRequests as e:\n",
    "                logging.warning(f\"Rate limit hit when fetching posts from r/{subreddit_name}: {e}\")\n",
    "                backoff_sleep(attempt)\n",
    "                attempt += 1\n",
    "            except RequestException as e:\n",
    "                logging.error(f\"Request exception when fetching posts from r/{subreddit_name}: {e}\")\n",
    "                backoff_sleep(attempt)\n",
    "                attempt += 1\n",
    "            except Exception as e:\n",
    "                logging.error(f\"Unexpected error when fetching posts from r/{subreddit_name}: {e}\")\n",
    "                break  # Saltar al siguiente subreddit\n",
    "        \n",
    "\n",
    "        for post_idx, post in enumerate(posts):\n",
    "            id = post.id\n",
    "            if id not in id_list:\n",
    "                id_list.append(id)\n",
    "\n",
    "                 # filtrar y guardar el título            \n",
    "                title_lables = []\n",
    "                if contains_trump_keyword(post.title):\n",
    "                    title_lables.append('trump')\n",
    "                if contains_trumper_keyword(post.title):\n",
    "                    title_lables.append('trumper')\n",
    "                if contains_kamala_keyword(post.title):\n",
    "                    title_lables.append('kamala')\n",
    "                if contains_kamaler_keyword(post.title):\n",
    "                    title_lables.append('kamaler')\n",
    "                if contains_democrat_keyword(post.title):\n",
    "                    title_lables.append('democrat')\n",
    "                if contains_republican_keyword(post.title):\n",
    "                    title_lables.append('republicans')\n",
    "                if len(title_lables) == 0:\n",
    "                    title_lables.append('none')\n",
    "\n",
    "                new_row = pd.DataFrame([{\n",
    "                    'text': post.title,\n",
    "                    'submission_type': 'title',\n",
    "                    'subreddit': subreddit_name,\n",
    "                    'labels': title_lables,\n",
    "                    'id': id\n",
    "                }])\n",
    "                df_buffer = pd.concat([df_buffer, new_row], ignore_index=True)\n",
    "                records_collected += 1\n",
    "                i +=1\n",
    "            \n",
    "                # while loop para los comments igual\n",
    "                attempt = 0\n",
    "                while True:\n",
    "                    try:\n",
    "                        post.comments.replace_more(limit=0) # flatten tree\n",
    "                        comments = post.comments.list()\n",
    "                        break # salimos del loop en caso de éxito\n",
    "                    \n",
    "                    except TooManyRequests as e:\n",
    "                        logging.warning(f\"Rate limit hit when fetching comments for post {post.id}: {e}\")\n",
    "                        backoff_sleep(attempt)\n",
    "                        attempt += 1\n",
    "                    except RequestException as e:\n",
    "                        logging.error(f\"Request exception when fetching comments for post {post.id}: {e}\")\n",
    "                        backoff_sleep(attempt)\n",
    "                        attempt += 1\n",
    "                    except Exception as e:\n",
    "                        logging.error(f\"Unexpected error when fetching comments for post {post.id}: {e}\")\n",
    "                        comments = []\n",
    "                        break  # Saltamos al siguiente post en caso de error\n",
    "                    \n",
    "                \n",
    "                for comment in comments:\n",
    "                    comment_labels = [] # creando la lista vacía de labels\n",
    "                    if not isinstance(comment, praw.models.Comment):\n",
    "                        continue  # Skippear si no es un comment válido\n",
    "\n",
    "                    # añadiendo etiquetas la lista de comment_labels\n",
    "                    if contains_trump_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('trump')\n",
    "                    if contains_trumper_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('trumper')\n",
    "                    if contains_kamala_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('kamala')\n",
    "                    if contains_kamaler_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('kamaler')\n",
    "                    if contains_democrat_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('democrat')\n",
    "                    if contains_republican_keyword(comment.body) and is_relevant_content(comment.body):\n",
    "                        comment_labels.append('republican')\n",
    "\n",
    "                    if len(comment_labels) == 0: # also get comments with no labels\n",
    "                        comment_labels.append('none')\n",
    "                    \n",
    "                    # metiendolo en los datos:\n",
    "                    new_row = pd.DataFrame([{\n",
    "                            'text': comment.body,\n",
    "                            'submission_type': 'comment',\n",
    "                            'subreddit': subreddit_name,\n",
    "                            'labels': comment_labels,\n",
    "                            'id': id\n",
    "                        }])\n",
    "                    df_buffer = pd.concat([df_buffer, new_row], ignore_index=True)\n",
    "                    records_collected += 1\n",
    "                    i +=1\n",
    "                                        \n",
    "                    # guardando el progreso periódicamente para liberar memoria\n",
    "                    if records_collected >= save_threshold:\n",
    "                        save_progress(df_buffer)\n",
    "                        df_buffer = pd.DataFrame(columns=columns)\n",
    "                        records_collected = 0\n",
    "                    \n",
    "        logging.info(f\"Finished scraping r/{subreddit_name}. i = {i}\")\n",
    "    \n",
    "    # guardando en caso de que se quede algo en el buffer\n",
    "    if not df_buffer.empty:\n",
    "        save_progress(df_buffer)\n",
    "        logging.info(f\"Finished scraping all subreddits. i = {i}\")\n",
    "        logging.info(f\"Number of unique posts scraped: {n_unique_posts}\")\n",
    "        logging.info(f\"Total number of id's: {len(id_list)}\")\n",
    "    \n",
    "\n",
    "# llamando la función\n",
    "all_hotscraped()\n",
    "\n",
    "# idea de procesamiento: tomar como referencia un post, y sentiment analysis a comments en base al post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekly Discussion Thread - week beginning Augu...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do we think about the PSL (Party for Soci...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Could I ask you guys to vote for either Woodc...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given that they appear to defend China against...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'republican']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rules clarification: Posts about the US electi...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eq921x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Thank you. The US elections are very important...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eq921x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>The political naivety among my progressive fri...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Best take I've seen on this is that the majori...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['kamala', 'kamaler']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jill Stein did not bother registering in enoug...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['kamala']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Yeah completely agree and you can see the effe...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['republican']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>It's basically Main Character Syndrome. Being ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>It is tragic, but reality, that our only alter...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trump', 'kamala', 'democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>In theory I support 3rd Parties but Jill Stein...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'democrat', 'republican']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Your best bet is maybe get them to dig into ho...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>Jill Stein is a Russian asset and its not even...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Jill Stein was seen eating dinner with Putin a...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I really do hate this situation. Not the post ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trump', 'trumper', 'kamala', 'democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>It reminds me of a friend of mine from Belgium...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>progressives for some reason get regressive wh...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'democrat']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>If you have friends that are doing this then y...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3d499</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 text submission_type  \\\n",
       "0   Weekly Discussion Thread - week beginning Augu...           title   \n",
       "1   What do we think about the PSL (Party for Soci...         comment   \n",
       "2   [Could I ask you guys to vote for either Woodc...         comment   \n",
       "3   Given that they appear to defend China against...         comment   \n",
       "4   Rules clarification: Posts about the US electi...           title   \n",
       "5   Thank you. The US elections are very important...         comment   \n",
       "6   The political naivety among my progressive fri...           title   \n",
       "7   Best take I've seen on this is that the majori...         comment   \n",
       "8   Jill Stein did not bother registering in enoug...         comment   \n",
       "9   Yeah completely agree and you can see the effe...         comment   \n",
       "10  It's basically Main Character Syndrome. Being ...         comment   \n",
       "11  It is tragic, but reality, that our only alter...         comment   \n",
       "12  In theory I support 3rd Parties but Jill Stein...         comment   \n",
       "13  Your best bet is maybe get them to dig into ho...         comment   \n",
       "14  Jill Stein is a Russian asset and its not even...         comment   \n",
       "15  Jill Stein was seen eating dinner with Putin a...         comment   \n",
       "16  I really do hate this situation. Not the post ...         comment   \n",
       "17  It reminds me of a friend of mine from Belgium...         comment   \n",
       "18  progressives for some reason get regressive wh...         comment   \n",
       "19  If you have friends that are doing this then y...         comment   \n",
       "\n",
       "          subreddit                                      labels       id  \n",
       "0   SocialDemocracy                                    ['none']  1f19fuf  \n",
       "1   SocialDemocracy                                    ['none']  1f19fuf  \n",
       "2   SocialDemocracy                                    ['none']  1f19fuf  \n",
       "3   SocialDemocracy                   ['trumper', 'republican']  1f19fuf  \n",
       "4   SocialDemocracy                                    ['none']  1eq921x  \n",
       "5   SocialDemocracy                                    ['none']  1eq921x  \n",
       "6   SocialDemocracy                                ['democrat']  1f3d499  \n",
       "7   SocialDemocracy                       ['kamala', 'kamaler']  1f3d499  \n",
       "8   SocialDemocracy                                  ['kamala']  1f3d499  \n",
       "9   SocialDemocracy                              ['republican']  1f3d499  \n",
       "10  SocialDemocracy                                ['democrat']  1f3d499  \n",
       "11  SocialDemocracy             ['trump', 'kamala', 'democrat']  1f3d499  \n",
       "12  SocialDemocracy       ['trumper', 'democrat', 'republican']  1f3d499  \n",
       "13  SocialDemocracy                                    ['none']  1f3d499  \n",
       "14  SocialDemocracy                                    ['none']  1f3d499  \n",
       "15  SocialDemocracy                     ['trumper', 'democrat']  1f3d499  \n",
       "16  SocialDemocracy  ['trump', 'trumper', 'kamala', 'democrat']  1f3d499  \n",
       "17  SocialDemocracy                                 ['trumper']  1f3d499  \n",
       "18  SocialDemocracy                     ['trumper', 'democrat']  1f3d499  \n",
       "19  SocialDemocracy                                    ['none']  1f3d499  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\all_hotscrape_v3.csv\")\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I really do hate this situation. Not the post itself—I actually agree with it. However, I can’t help but feel that they would find another reason not to vote for the Democrats, even if the Democrats were supporting the Palestinian people. I do dislike Harris because she isn’t doing enough to stop the genocide, but at the same time, it’s hard to fight a genocide abroad when there’s a risk of one happening at home if Trump returns to power if what I read about project 2025 is true. I know I am naive, so I could be wrong, so I’m open to being corrected. Don’t yell at me if I am wrong instead explain why I am wrong please. Also sorry if my grammar or typing is bad, I’m not good at this.\n"
     ]
    }
   ],
   "source": [
    "print(df.iloc[16, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(247582, 5)\n",
      "Total duplicates: 7075\n",
      "Total NaNs: text               3\n",
      "submission_type    0\n",
      "subreddit          0\n",
      "labels             0\n",
      "id                 0\n",
      "dtype: int64\n",
      "(240504, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(f\"Total duplicates: {df.duplicated().sum()}\")\n",
    "df = df.drop_duplicates()\n",
    "print(f\"Total NaNs: {df.isna().sum()}\")\n",
    "df = df.dropna()\n",
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240504, 5)\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(240504, 5)\n",
      "6245\n",
      "submission_type\n",
      "comment    226987\n",
      "title       13517\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(len(df['id'].unique()))\n",
    "print(df['submission_type'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "909"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df[df['submission_type'] == 'title']\n",
    "\n",
    "vcs = titles['id'].value_counts()\n",
    "\n",
    "vcsrepes = vcs[vcs>1]\n",
    "len(vcsrepes)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "909\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>186591</th>\n",
       "      <td>I know they're just happy kids celebrating a w...</td>\n",
       "      <td>title</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>['republicans']</td>\n",
       "      <td>1dy44ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200642</th>\n",
       "      <td>I know they're just happy kids celebrating a w...</td>\n",
       "      <td>title</td>\n",
       "      <td>ModeratePolitics</td>\n",
       "      <td>['republicans']</td>\n",
       "      <td>1dy44ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130387</th>\n",
       "      <td>I know they're just happy kids celebrating a w...</td>\n",
       "      <td>title</td>\n",
       "      <td>WayOfTheBern</td>\n",
       "      <td>['republicans']</td>\n",
       "      <td>1dy44ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144438</th>\n",
       "      <td>I know they're just happy kids celebrating a w...</td>\n",
       "      <td>title</td>\n",
       "      <td>politics</td>\n",
       "      <td>['republicans']</td>\n",
       "      <td>1dy44ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>158489</th>\n",
       "      <td>I know they're just happy kids celebrating a w...</td>\n",
       "      <td>title</td>\n",
       "      <td>PoliticalDiscussion</td>\n",
       "      <td>['republicans']</td>\n",
       "      <td>1dy44ap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130715</th>\n",
       "      <td>Bangladesh: the ‘Global South’ debt crisis int...</td>\n",
       "      <td>title</td>\n",
       "      <td>politics</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3j7qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172868</th>\n",
       "      <td>Bangladesh: the ‘Global South’ debt crisis int...</td>\n",
       "      <td>title</td>\n",
       "      <td>Liberal</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3j7qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116664</th>\n",
       "      <td>Bangladesh: the ‘Global South’ debt crisis int...</td>\n",
       "      <td>title</td>\n",
       "      <td>WayOfTheBern</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3j7qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186919</th>\n",
       "      <td>Bangladesh: the ‘Global South’ debt crisis int...</td>\n",
       "      <td>title</td>\n",
       "      <td>ModeratePolitics</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3j7qw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144766</th>\n",
       "      <td>Bangladesh: the ‘Global South’ debt crisis int...</td>\n",
       "      <td>title</td>\n",
       "      <td>PoliticalDiscussion</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f3j7qw</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8181 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text submission_type  \\\n",
       "186591  I know they're just happy kids celebrating a w...           title   \n",
       "200642  I know they're just happy kids celebrating a w...           title   \n",
       "130387  I know they're just happy kids celebrating a w...           title   \n",
       "144438  I know they're just happy kids celebrating a w...           title   \n",
       "158489  I know they're just happy kids celebrating a w...           title   \n",
       "...                                                   ...             ...   \n",
       "130715  Bangladesh: the ‘Global South’ debt crisis int...           title   \n",
       "172868  Bangladesh: the ‘Global South’ debt crisis int...           title   \n",
       "116664  Bangladesh: the ‘Global South’ debt crisis int...           title   \n",
       "186919  Bangladesh: the ‘Global South’ debt crisis int...           title   \n",
       "144766  Bangladesh: the ‘Global South’ debt crisis int...           title   \n",
       "\n",
       "                  subreddit           labels       id  \n",
       "186591              Liberal  ['republicans']  1dy44ap  \n",
       "200642     ModeratePolitics  ['republicans']  1dy44ap  \n",
       "130387         WayOfTheBern  ['republicans']  1dy44ap  \n",
       "144438             politics  ['republicans']  1dy44ap  \n",
       "158489  PoliticalDiscussion  ['republicans']  1dy44ap  \n",
       "...                     ...              ...      ...  \n",
       "130715             politics         ['none']  1f3j7qw  \n",
       "172868              Liberal         ['none']  1f3j7qw  \n",
       "116664         WayOfTheBern         ['none']  1f3j7qw  \n",
       "186919     ModeratePolitics         ['none']  1f3j7qw  \n",
       "144766  PoliticalDiscussion         ['none']  1f3j7qw  \n",
       "\n",
       "[8181 rows x 5 columns]"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplicate_ids = titles[titles.duplicated('id', keep=False)]['id'].unique()\n",
    "\n",
    "print(len(duplicate_ids))\n",
    "\n",
    "repes = titles[titles['id'].isin(duplicate_ids)]\n",
    "\n",
    "repes = repes.sort_values(by='id')\n",
    "repes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text duplicates: 0\n",
      "Nans (removed dupes):\n",
      " text               0\n",
      "submission_type    0\n",
      "subreddit          0\n",
      "labels             0\n",
      "id                 0\n",
      "dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\34616\\AppData\\Local\\Temp\\ipykernel_24276\\469040774.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['text'] = df['text'].drop_duplicates()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Weekly Discussion Thread - week beginning Augu...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>What do we think about the PSL (Party for Soci...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[Could I ask you guys to vote for either Woodc...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Given that they appear to defend China against...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'republican']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Rules clarification: Posts about the US electi...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eq921x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247577</th>\n",
       "      <td>In today's news, the water is wet</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eg2q8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247578</th>\n",
       "      <td>This is exactly why I plan to vote Trump</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>['trump']</td>\n",
       "      <td>1eg2q8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247579</th>\n",
       "      <td>They rate it that way because it is, and Trump...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>['trump']</td>\n",
       "      <td>1eg2q8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247580</th>\n",
       "      <td>Don't tell Lichtman</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eg2q8p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247581</th>\n",
       "      <td>Is this really news to some people??</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eg2q8p</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>126260 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text submission_type  \\\n",
       "0       Weekly Discussion Thread - week beginning Augu...           title   \n",
       "1       What do we think about the PSL (Party for Soci...         comment   \n",
       "2       [Could I ask you guys to vote for either Woodc...         comment   \n",
       "3       Given that they appear to defend China against...         comment   \n",
       "4       Rules clarification: Posts about the US electi...           title   \n",
       "...                                                   ...             ...   \n",
       "247577                  In today's news, the water is wet         comment   \n",
       "247578           This is exactly why I plan to vote Trump         comment   \n",
       "247579  They rate it that way because it is, and Trump...         comment   \n",
       "247580                                Don't tell Lichtman         comment   \n",
       "247581               Is this really news to some people??         comment   \n",
       "\n",
       "              subreddit                     labels       id  \n",
       "0       SocialDemocracy                   ['none']  1f19fuf  \n",
       "1       SocialDemocracy                   ['none']  1f19fuf  \n",
       "2       SocialDemocracy                   ['none']  1f19fuf  \n",
       "3       SocialDemocracy  ['trumper', 'republican']  1f19fuf  \n",
       "4       SocialDemocracy                   ['none']  1eq921x  \n",
       "...                 ...                        ...      ...  \n",
       "247577       Republican                   ['none']  1eg2q8p  \n",
       "247578       Republican                  ['trump']  1eg2q8p  \n",
       "247579       Republican                  ['trump']  1eg2q8p  \n",
       "247580       Republican                   ['none']  1eg2q8p  \n",
       "247581       Republican                   ['none']  1eg2q8p  \n",
       "\n",
       "[126260 rows x 5 columns]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Text duplicates: {df['text'].duplicated().sum()}\")\n",
    "df['text'] = df['text'].drop_duplicates()\n",
    "print(f\"Nans (removed dupes):\\n {df.isna().sum()}\")\n",
    "df = df.dropna()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126260, 5)\n",
      "6211\n",
      "submission_type\n",
      "comment    120193\n",
      "title        6067\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(len(df['id'].unique()))\n",
    "print(df['submission_type'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [text, submission_type, subreddit, labels, id]\n",
       "Index: []"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titles = df[df['submission_type'] == 'title']\n",
    "duplicate_ids = titles[titles.duplicated('id', keep=False)]['id'].unique()\n",
    "print(len(duplicate_ids))\n",
    "repes = titles[titles['id'].isin(duplicate_ids)]\n",
    "repes = repes.sort_values(by='id')\n",
    "repes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\all_hotscrape_v3.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>labels</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Weekly Discussion Thread - week beginning Augu...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>What do we think about the PSL (Party for Soci...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>[Could I ask you guys to vote for either Woodc...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Given that they appear to defend China against...</td>\n",
       "      <td>comment</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['trumper', 'republican']</td>\n",
       "      <td>1f19fuf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Rules clarification: Posts about the US electi...</td>\n",
       "      <td>title</td>\n",
       "      <td>SocialDemocracy</td>\n",
       "      <td>['none']</td>\n",
       "      <td>1eq921x</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               text  \\\n",
       "0           0  Weekly Discussion Thread - week beginning Augu...   \n",
       "1           1  What do we think about the PSL (Party for Soci...   \n",
       "2           2  [Could I ask you guys to vote for either Woodc...   \n",
       "3           3  Given that they appear to defend China against...   \n",
       "4           4  Rules clarification: Posts about the US electi...   \n",
       "\n",
       "  submission_type        subreddit                     labels       id  \n",
       "0           title  SocialDemocracy                   ['none']  1f19fuf  \n",
       "1         comment  SocialDemocracy                   ['none']  1f19fuf  \n",
       "2         comment  SocialDemocracy                   ['none']  1f19fuf  \n",
       "3         comment  SocialDemocracy  ['trumper', 'republican']  1f19fuf  \n",
       "4           title  SocialDemocracy                   ['none']  1eq921x  "
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check = pd.read_csv(r\"C:\\Users\\34616\\Documents\\4GEEKS\\datos_gordos\\reddit\\Scraping_results\\all_hotscrape_v3.csv\")\n",
    "df_check.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(126260, 5)\n",
      "text               0\n",
      "submission_type    0\n",
      "subreddit          0\n",
      "labels             0\n",
      "id                 0\n",
      "dtype: int64\n",
      "0\n",
      "text: \n",
      "0\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.isna().sum())\n",
    "print(df.duplicated().sum())\n",
    "print(\"text: \")\n",
    "print(df['text'].duplicated().sum())\n",
    "print(df['text'].isna().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SocialDemocracy',\n",
       " 'USPolitics',\n",
       " 'Libertarian',\n",
       " 'ConservativesOnly',\n",
       " 'OurPresident',\n",
       " 'Socialism',\n",
       " 'WayOfTheBern',\n",
       " 'politics',\n",
       " 'PoliticalDiscussion',\n",
       " 'Conservative',\n",
       " 'Liberal',\n",
       " 'ModeratePolitics',\n",
       " 'Ask_Politics',\n",
       " 'Democrats',\n",
       " 'Republican']"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subreddits_original_list = ['SocialDemocracy', 'USPolitics', 'Libertarian', 'ConservativesOnly', 'OurPresident', 'Socialism', 'WayOfTheBern', 'politics', 'PoliticalDiscussion', 'Conservative', 'Liberal', 'ModeratePolitics', 'Ask_Politics', 'Democrats', 'Republican']\n",
    "subreddits_original_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subreddit\n",
       "Libertarian          34060\n",
       "OurPresident         31177\n",
       "SocialDemocracy      25786\n",
       "Republican           16843\n",
       "Socialism            12394\n",
       "USPolitics            4360\n",
       "ConservativesOnly     1640\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_check['subreddit'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "GPU_Chiclanera",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
