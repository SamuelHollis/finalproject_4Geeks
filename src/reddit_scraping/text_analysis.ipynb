{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Análisis de la longitud de los textos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from nltk import download\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Media: Nobody knows what kamala is about\\n\\nMe...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>kamala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NYT breaking news that Netanyahu has agreed to...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trumper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I love how the stock crash 2 weeks ago was HUG...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I was thinking this morning about how freaking...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trumper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Conservative in a purple state. I'm voting for...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text submission_type  \\\n",
       "0  Media: Nobody knows what kamala is about\\n\\nMe...         comment   \n",
       "1  NYT breaking news that Netanyahu has agreed to...         comment   \n",
       "2  I love how the stock crash 2 weeks ago was HUG...         comment   \n",
       "3  I was thinking this morning about how freaking...         comment   \n",
       "4  Conservative in a purple state. I'm voting for...         comment   \n",
       "\n",
       "  subreddit    label  \n",
       "0  politics   kamala  \n",
       "1  politics  trumper  \n",
       "2  politics    trump  \n",
       "3  politics  trumper  \n",
       "4  politics    trump  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds = pd.read_csv(r'C:\\Users\\10and\\OneDrive\\Documentos\\GitHub\\4geeks_finalproject_modeling\\data\\raw\\all_hotscrape_v2(elbueno).csv')\n",
    "\n",
    "text_ds.head(5)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Procesamiento del texto:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    # Convertir el texto a minúsculas\n",
    "    text = text.lower()\n",
    "\n",
    "    # Eliminar cualquier carácter que no sea una letra (a-z) o un espacio en blanco ( )\n",
    "    text = re.sub(r'[^a-z ]', \" \", text)\n",
    "\n",
    "    # Eliminar espacios en blanco\n",
    "    text = re.sub(r'\\s+[a-zA-Z]\\s+', \" \", text)\n",
    "    text = re.sub(r'\\^[a-zA-Z]\\s+', \" \", text)\n",
    "\n",
    "    # Reducir espacios en blanco múltiples a uno único\n",
    "    text = re.sub(r'\\s+', \" \", text)\n",
    "\n",
    "    # Eliminar tags\n",
    "    text = re.sub(\"&lt;/?.*?&gt;\", \" &lt;&gt; \", text)\n",
    "\n",
    "    return text.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a nuestro dataset:\n",
    "text_ds['text'] = text_ds['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lematización: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Instanciamos el lematizador:\n",
    "download(\"wordnet\")\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "download(\"stopwords\")\n",
    "stop_words = stopwords.words(\"english\")\n",
    "\n",
    "def lemmatize_text(words, lemmatizer = lemmatizer):\n",
    "    # lematiza\n",
    "    tokens = [lemmatizer.lemmatize(word) for word in words]\n",
    "    # saca stop words\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "    # se queda con las de largo mayor a\n",
    "    tokens = [word for word in tokens if len(word) > 3]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplicamos la función a nuestro dataset:\n",
    "text_ds['text'] = text_ds['text'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Palabras más frecuentes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n",
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package omw-1.4 is already up-to-date!\n",
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     C:\\Users\\10and\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('omw-1.4')\n",
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convertir las listas en cadenas de texto\n",
    "text_ds['text'] = text_ds['text'].apply(lambda x: ' '.join(x) if isinstance(x, list) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "medium nobody know k\n"
     ]
    }
   ],
   "source": [
    "all_words = ' '.join(text.lower() for text in text_ds['text'])\n",
    "print(all_words[:20])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>submission_type</th>\n",
       "      <th>subreddit</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>medium nobody know kamala medium back nonstop ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>kamala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>breaking news netanyahu agreed term ceasefire ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trumper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>love stock crash week huge news every station ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>thinking morning freaking immaculate past mont...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trumper</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conservative purple state voting harris hell o...</td>\n",
       "      <td>comment</td>\n",
       "      <td>politics</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187608</th>\n",
       "      <td>would apply trump lost fundamentally different...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187609</th>\n",
       "      <td>many pardon trump issued</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187610</th>\n",
       "      <td>well trump felon</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>trump</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187611</th>\n",
       "      <td>post keep blasting harris shit even political ...</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>kamala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187612</th>\n",
       "      <td>kamala love felon great debate</td>\n",
       "      <td>comment</td>\n",
       "      <td>Republican</td>\n",
       "      <td>kamala</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187613 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text submission_type  \\\n",
       "0       medium nobody know kamala medium back nonstop ...         comment   \n",
       "1       breaking news netanyahu agreed term ceasefire ...         comment   \n",
       "2       love stock crash week huge news every station ...         comment   \n",
       "3       thinking morning freaking immaculate past mont...         comment   \n",
       "4       conservative purple state voting harris hell o...         comment   \n",
       "...                                                   ...             ...   \n",
       "187608  would apply trump lost fundamentally different...         comment   \n",
       "187609                           many pardon trump issued         comment   \n",
       "187610                                   well trump felon         comment   \n",
       "187611  post keep blasting harris shit even political ...         comment   \n",
       "187612                     kamala love felon great debate         comment   \n",
       "\n",
       "         subreddit    label  \n",
       "0         politics   kamala  \n",
       "1         politics  trumper  \n",
       "2         politics    trump  \n",
       "3         politics  trumper  \n",
       "4         politics    trump  \n",
       "...            ...      ...  \n",
       "187608  Republican    trump  \n",
       "187609  Republican    trump  \n",
       "187610  Republican    trump  \n",
       "187611  Republican   kamala  \n",
       "187612  Republican   kamala  \n",
       "\n",
       "[187613 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_freq = Counter(word_tokenize(all_words, language='english', preserve_line=True))\n",
    "common_words = word_freq.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('trump', 121040),\n",
       " ('people', 66065),\n",
       " ('would', 58251),\n",
       " ('biden', 50604),\n",
       " ('like', 49349),\n",
       " ('think', 43157),\n",
       " ('vote', 33438),\n",
       " ('even', 31504),\n",
       " ('state', 30262),\n",
       " ('right', 29058),\n",
       " ('thing', 26353),\n",
       " ('time', 26030),\n",
       " ('party', 25149),\n",
       " ('election', 24410),\n",
       " ('republican', 23861),\n",
       " ('also', 23768),\n",
       " ('want', 23687),\n",
       " ('make', 23639),\n",
       " ('year', 23635),\n",
       " ('harris', 23597)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "common_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ds.to_csv('preprocess_text', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "label\n",
       "trump      85349\n",
       "trumper    85158\n",
       "kamala     11697\n",
       "kamaler     5409\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ds['label'].value_counts()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
